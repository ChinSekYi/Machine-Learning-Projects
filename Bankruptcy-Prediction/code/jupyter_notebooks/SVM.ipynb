{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from scipy.io import arff\n",
    "import data_processing as dp\n",
    "import warnings\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data = arff.loadarff(\"../../data/3year.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "df_origin = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type_ = \"linear\"  # global\n",
    "\n",
    "\n",
    "def SVM_return_model(*args, kernel_type_):\n",
    "    X_train = args[0]\n",
    "    X_test = args[1]\n",
    "    y_train = args[2]\n",
    "    y_test = args[3]\n",
    "\n",
    "    # Reset indices to ensure alignment\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Training the SVM model\n",
    "    svm_model = SVC(kernel=kernel_type_)\n",
    "    print(f\"\\nkernel_type: {kernel_type_}\")\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the testing set\n",
    "    y_pred_train = svm_model.predict(X_train)\n",
    "    y_pred_test = svm_model.predict(X_test)\n",
    "\n",
    "    # Evaluating the model\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    precision_score_ = precision_score(y_test, y_pred_test)\n",
    "    recall_score_ = recall_score(y_test, y_pred_test)\n",
    "    f1_score_ = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    # print(classification_report(y_test, y_pred_test))\n",
    "    print(f\"train_accuracy: {train_accuracy}\")\n",
    "    print(f\"test_accuracy: {test_accuracy}\")\n",
    "    print(f\"precision_score: {precision_score_}\")\n",
    "    print(f\"recall_score: {recall_score_}\")\n",
    "    print(f\"f1_score: {f1_score_}\")\n",
    "\n",
    "    return svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13978, 30)\n"
     ]
    }
   ],
   "source": [
    "train_test_dataset = dp.pre_process(df)\n",
    "print(train_test_dataset[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prelim check on different kernel_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mlinear\u001b[00m\n",
      "\n",
      "kernel_type: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy: 0.537201316354271\n",
      "test_accuracy: 0.5728340209457315\n",
      "precision_score: 0.04708520179372197\n",
      "recall_score: 0.4701492537313433\n",
      "f1_score: 0.08559782608695651\n",
      "\u001b[96mpoly\u001b[00m\n",
      "\n",
      "kernel_type: poly\n",
      "train_accuracy: 0.5633853197882387\n",
      "test_accuracy: 0.510631545541098\n",
      "precision_score: 0.04813863928112965\n",
      "recall_score: 0.5597014925373134\n",
      "f1_score: 0.08865248226950355\n",
      "\u001b[96mrbf\u001b[00m\n",
      "\n",
      "kernel_type: rbf\n",
      "train_accuracy: 0.5304764630133066\n",
      "test_accuracy: 0.5147572199301809\n",
      "precision_score: 0.04795852235904083\n",
      "recall_score: 0.5522388059701493\n",
      "f1_score: 0.08825283243887895\n",
      "\u001b[96msigmoid\u001b[00m\n",
      "\n",
      "kernel_type: sigmoid\n",
      "train_accuracy: 0.5241808556302762\n",
      "test_accuracy: 0.5893367185020628\n",
      "precision_score: 0.04258675078864353\n",
      "recall_score: 0.40298507462686567\n",
      "f1_score: 0.07703281027104138\n"
     ]
    }
   ],
   "source": [
    "kernel_list = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "kernel_dict = dict()\n",
    "\n",
    "for kernel_type in kernel_list:\n",
    "    print(f\"\\033[96m{kernel_type}\\033[00m\")\n",
    "    model = SVM_return_model(*train_test_dataset, kernel_type_=kernel_type)\n",
    "\n",
    "# we found that sigmoid gives the best test accuracy\n",
    "best_kernel_type = \"sigmoid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ANOVA test for feature selection to find the best number of k features for our dataset  \n",
    "Result: \n",
    "- Best k for train_accuracy: 23\n",
    "- Best k for test_accuracy: 25\n",
    "\n",
    "Hence, we use k = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best number of features that gives the highest test accuracy for SVM model\n",
    "def SVM_sigmoid_model(*args):  # for ANOVA\n",
    "    X_train = args[0]\n",
    "    X_test = args[1]\n",
    "    y_train = args[2]\n",
    "    y_test = args[3]\n",
    "\n",
    "    # Reset indices to ensure alignment\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    model = SVM_return_model(*args, kernel_type_=\"sigmoid\")\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Evaluating the model\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "\n",
    "# best_train_test_dataset = dp.find_best_k_features_from_ANOVA(\n",
    "#    SVM_sigmoid_model, *train_test_dataset\n",
    "# )\n",
    "\n",
    "# print(len(best_train_test_dataset[0].columns))\n",
    "# Best k for train_accuracy: 23\n",
    "# Best k for test_accuracy: 25\n",
    "\n",
    "# for quick run\n",
    "k_features = 25\n",
    "best_train_test_dataset = dp.get_df_with_top_k_features(k_features, *train_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a SVM model based on the top 25 features after ANOVA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kernel_type: sigmoid\n",
      "train_accuracy: 0.528544856202604\n",
      "test_accuracy: 0.6013963821009204\n",
      "precision_score: 0.041666666666666664\n",
      "recall_score: 0.3805970149253731\n",
      "f1_score: 0.0751104565537555\n"
     ]
    }
   ],
   "source": [
    "# current best SVM model after ANOVA test\n",
    "SVM_model2 = SVM_return_model(*best_train_test_dataset, kernel_type_=best_kernel_type)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = best_train_test_dataset\n",
    "conf_matrix = confusion_matrix(y_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve model accuracy, we perform GridSearch to find the best model hyperparameters for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV\n",
    "https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10, 100, 1000],\n",
    "    \"gamma\": [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "}\n",
    "\n",
    "# grid = GridSearchCV(SVM_model2, param_grid, refit=True, verbose=3)\n",
    "\n",
    "# fitting the model for grid search\n",
    "# grid.fit(X_train1, y_train1)\n",
    "\n",
    "# print best parameter after tuning\n",
    "# print(grid.best_params_)\n",
    "\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From grid-search above, we found that the best hyperparameters are:\n",
    "C=1, gamma=0.1, kernel=poly\n",
    "Where the average accuracy score after cross-validation is 0.5122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVC model with specified parameters\n",
    "svm_model_after_gridsearch = SVC(C=1, gamma=0.1, kernel=\"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model without grid-search\n",
      "[[1744 1273]\n",
      " [  71   63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.58      0.72      3017\n",
      "           1       0.05      0.47      0.09       134\n",
      "\n",
      "    accuracy                           0.57      3151\n",
      "   macro avg       0.50      0.52      0.40      3151\n",
      "weighted avg       0.92      0.57      0.69      3151\n",
      "\n",
      "precision_score: 0.04715568862275449\n",
      "recall_score: 0.4701492537313433\n",
      "train_accuracy: 0.5372728573472599\n",
      "test_accuracy: 0.5734687400825135\n",
      "f1score: 0.0857142857142857\n",
      "\n",
      "SVM model with grid-search\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.54      0.64      6989\n",
      "           1       0.65      0.86      0.74      6989\n",
      "\n",
      "    accuracy                           0.70     13978\n",
      "   macro avg       0.72      0.70      0.69     13978\n",
      "weighted avg       0.72      0.70      0.69     13978\n",
      "\n",
      "[[1606 1411]\n",
      " [  31  103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.53      0.69      3017\n",
      "           1       0.07      0.77      0.13       134\n",
      "\n",
      "    accuracy                           0.54      3151\n",
      "   macro avg       0.52      0.65      0.41      3151\n",
      "weighted avg       0.94      0.54      0.67      3151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test1)\n",
    "\n",
    "# print classification report (without grid search)\n",
    "print(\"SVM model without grid-search\")\n",
    "y_pred_test = SVM_model2.predict(X_test1)\n",
    "print(confusion_matrix(y_test1, y_pred_test))\n",
    "clf = SVM_return_model(\n",
    "    *best_train_test_dataset, best_kernel_type\n",
    ")  # to print accuracy score\n",
    "\n",
    "# print classification report with grid search\n",
    "print(\"\\nSVM model with grid-search\")\n",
    "print(confusion_matrix(y_test1, grid_predictions))\n",
    "print(classification_report(y_test1, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging to improve prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55950491907331\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# W/O GRID\n",
    "\n",
    "# Define the BaggingClassifier\n",
    "bagging_svm = BaggingClassifier(\n",
    "    SVM_model2, n_estimators=10, random_state=42\n",
    ")  # Adjust n_estimators as needed\n",
    "\n",
    "# Train the BaggingClassifier on your training data\n",
    "bagging_svm.fit(X_train1, y_train1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = bagging_svm.score(X_test1, y_test1)\n",
    "print(\"Accuracy:\", accuracy)  # 0.55950491907331"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
